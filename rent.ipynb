{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-27T01:52:15.522713",
     "start_time": "2017-02-27T01:52:09.100332"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['boro', 'uf1_1', 'uf1_2', 'uf1_3', 'uf1_4', 'uf1_5', 'uf1_6', 'uf1_7',\n",
      "       'uf1_8', 'uf1_9', 'uf1_10', 'uf1_11', 'uf1_12', 'uf1_13', 'uf1_14',\n",
      "       'uf1_15', 'uf1_16', 'uf1_35', 'uf1_17', 'uf1_18', 'uf1_19', 'uf1_20',\n",
      "       'uf1_21', 'uf1_22', 'sc23', 'sc24', 'sc36', 'sc37', 'sc38', 'sc114',\n",
      "       'uf48', 'sc147', 'uf11', 'sc149', 'sc173', 'sc171', 'sc150', 'sc151',\n",
      "       'sc152', 'sc153', 'sc154', 'sc155', 'sc156', 'sc157', 'sc158', 'uf17',\n",
      "       'sc181', 'sc185', 'sc186', 'sc197', 'sc198', 'sc187', 'sc188', 'sc571',\n",
      "       'sc189', 'sc190', 'sc191', 'sc192', 'sc193', 'sc194', 'sc196', 'sc199',\n",
      "       'sc575', 'uf19', 'new_csr', 'rec15', 'sc26', 'uf23', 'rec21', 'rec62',\n",
      "       'rec64', 'rec54', 'rec53', 'cd'],\n",
      "      dtype='object', name=0)\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import csv\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Download the csv file and store it as a pandas dataframe\n",
    "\n",
    "\n",
    "data = urllib.request.urlopen('https://ndownloader.figshare.com/files/7586326')\n",
    "f = csv.reader(io.TextIOWrapper(data))\n",
    "dataset = list(f)\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "#Assign row 0 to the be the column names\n",
    "#Drop the feature columns that are related to occupants and not apartments\n",
    "#Drop the feature columns that are related to owner occupied properties\n",
    "#Drop rows for which the \"Monthly Contract Rent\" column (the response variable) has a missing value\n",
    "#Drop rows with missing values\n",
    "\n",
    "\n",
    "df.columns = df.iloc[0]\n",
    "dropped = [0] + list(range(30,44)) + list(range(45,65)) + [89,90,93,94,95,96,97,98,113,114,115,116] + list(\n",
    "    range(119,124)) + list(range(130,136)) + list(range(140,162)) + list(range(163,197)) + list(range(80,89))\n",
    "df = df.drop(df[df.uf17 == '99999'].index)\n",
    "df = df.drop(df.columns[[dropped]], axis = 1)\n",
    "df = df.drop(df[df.uf1_1 == '8'].index)\n",
    "df = df.drop(df[df.uf1_7 == '8'].index)\n",
    "df = df.drop(df[df.uf1_12 == '8'].index)\n",
    "df = df.drop(df[df.uf1_17 == '8'].index)\n",
    "df = df.drop(df[df.sc23 == '8'].index)\n",
    "df = df.drop(df[df.sc24 == '8'].index)\n",
    "df = df.drop(df[df.sc36 == '8'].index)\n",
    "df = df.drop(df[df.sc37 == '8'].index)\n",
    "df = df.drop(df[df.sc38 == '8'].index)\n",
    "df = df.drop(df[df.sc114 == '4'].index)\n",
    "df = df.drop(df[df.sc147 == '8'].index)\n",
    "df = df.drop(df[df.sc173 == '8'].index)\n",
    "df = df.drop(df[df.sc171 == '8'].index)\n",
    "df = df.drop(df[df.sc154 == '8'].index)\n",
    "df = df.drop(df[df.sc157 == '8'].index)\n",
    "df = df.drop(df[df.sc185 == '8'].index)\n",
    "df = df.drop(df[df.sc197 == '8'].index)\n",
    "df = df.drop(df[df.sc198 == '8'].index)\n",
    "df = df.drop(df[df.sc187 == '8'].index)\n",
    "df = df.drop(df[df.sc188 == '8'].index)\n",
    "df = df.drop(df[df.sc189 == '8'].index)\n",
    "df = df.drop(df[df.sc190 == '8'].index)\n",
    "df = df.drop(df[df.sc191 == '8'].index)\n",
    "df = df.drop(df[df.sc192 == '8'].index)\n",
    "df = df.drop(df[df.sc194 == '8'].index)\n",
    "df = df.drop(df[df.sc196 == '8'].index)\n",
    "df = df.drop(df[df.sc199 == '8'].index)\n",
    "df = df.drop(df[df.sc575 == '8'].index)\n",
    "df = df.drop(df[df.rec15 == '10'].index)\n",
    "df = df.drop(df[df.rec15 == '12'].index)\n",
    "\n",
    "print(df.columns)\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-27T01:52:22.426282",
     "start_time": "2017-02-27T01:52:22.351708"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uf48', 'uf11', 'sc150', 'sc151', 'uf17', 'sc181', 'sc186', 'sc571',\n",
      "       'uf23', 'rec54',\n",
      "       ...\n",
      "       'cd_10', 'cd_11', 'cd_12', 'cd_13', 'cd_14', 'cd_15', 'cd_16', 'cd_17',\n",
      "       'cd_18', 'cd_cd'],\n",
      "      dtype='object', length=273)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 73]\n"
     ]
    }
   ],
   "source": [
    "#Create a new dataframe by performing one hot encoding on the remaining columns that contain categorical features\n",
    "\n",
    "\n",
    "cat_var = list(range(0,30)) + [31,33,34,35] + list(range(38,45)) + [47,49,50,51,52] + list(range(54,67)) + [68,69,70,73] \n",
    "df_OHE = pd.get_dummies(df, columns = df.columns[[cat_var]])\n",
    "print(df_OHE.columns)\n",
    "print(cat_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-27T01:52:24.886184",
     "start_time": "2017-02-27T01:52:24.728006"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uf48' 'uf11' 'sc150' 'sc151' 'uf17' 'sc181' 'sc186' 'sc571' 'uf23'\n",
      " 'rec54' 'rec53' 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1]\n",
      "(6859, 273)\n",
      "[ 11.   4.   5.   4.   2.   9.   1.   8.   1.   1.   1.   0.   0.   0.   0.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   1.   0.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   1.   0.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   1.   0.   0.   0.   1.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   1.\n",
      "   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.\n",
      "   1.   0.   1.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   1.   0.   0.   0.   1.   0.   0.   0.   0.   1.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   0.   1.   0.   0.   0.   0.   1.\n",
      "   0.   0.   1.   0.   0.   0.   0.   1.   0.   0.   0.   1.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   1.   0.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   1.   0.   0.   1.   0.   0.   0.   1.   0.   0.   1.   0.   0.\n",
      "   1.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.\n",
      "   0.   0.   1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "[ 850.  600.  998. ...,  100.  600.  250.]\n"
     ]
    }
   ],
   "source": [
    "#Convert the dataframe to a Numpy array\n",
    "#Delete the row of column labels\n",
    "#Convert entries from string to int\n",
    "#Remove the \"Monthly Contract Rent\" column from the feature columns\n",
    "\n",
    "\n",
    "housing = df_OHE.as_matrix()\n",
    "print(housing[0,:])\n",
    "housing = np.delete(housing, (0), axis=0)\n",
    "housing = housing.astype(np.float)\n",
    "\n",
    "print(np.shape(housing))\n",
    "\n",
    "rent = housing[:,4]\n",
    "housing = np.delete(housing, 4, axis=1)\n",
    "print(housing[0,:])\n",
    "print(rent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-27T02:22:21.527174",
     "start_time": "2017-02-27T02:22:21.502132"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Use GridSearchCV to find the best value for alpha\n",
    "\n",
    "def grid_rent(data, target):\n",
    "    \"\"\"\"\"\"\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    X, y = data, target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5, train_size = .8)\n",
    "    pipe = Pipeline((('scaler', StandardScaler()),\n",
    "                    ('ridge', Ridge())))\n",
    "    param_grid = {'ridge__alpha': range(1,50)}\n",
    "    grid = GridSearchCV(pipe, param_grid, cv = 10)\n",
    "    grid.fit(X_train, y_train)\n",
    "    #scores = cross_val_score(pipe, X_train, y_train, cv = KFold(n_splits = 10, shuffle = True, random_state = 5))\n",
    "    #return('mean:', np.mean(scores), 'standard deviation:', np.std(scores), 'scores:', scores)\n",
    "    a = grid.best_params_['ridge__alpha']\n",
    "    print(a, grid.score(X_test, y_test))\n",
    "    return(a)\n",
    "\n",
    "\n",
    "def score_rent(data, target, a):\n",
    "    \"\"\"\"\"\"\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    X, y = data, target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5, train_size = .8)\n",
    "    pipe = Pipeline((('scaler', StandardScaler()),\n",
    "                    ('ridge', Ridge(alpha = a))))\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv = KFold(n_splits = 10, shuffle = True, random_state = 5))\n",
    "    #print('mean:', np.mean(scores), 'standard deviation:', np.std(scores), 'scores:', scores)\n",
    "    return(np.mean(scores))\n",
    "\n",
    "\n",
    "def predict_rent(data, target):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return('test data:', X_test, 'true labels:', y_test, 'predicted labels:', Ridge.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-27T02:18:47.689586",
     "start_time": "2017-02-27T02:17:39.933530"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 0.498531675894\n",
      "mean: 0.500076575713 standard deviation: 0.0330890144362 scores: [ 0.49091771  0.50490745  0.53490077  0.53562563  0.54486577  0.4341657\n",
      "  0.4737611   0.51050794  0.50545495  0.46565874]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50007657571333741"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "score_rent(housing, rent, grid_rent(housing,rent))\n",
    "#predict_rent(housing, rent)\n",
    "\n",
    "#cat_var = list(range(0,30)) + [31,33,34,35] + list(range(38,46)) + [47,50,56,58,59,60,61] + list(range(63,76)) + [77,78,79,82] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-22T00:36:56.922537",
     "start_time": "2017-02-22T00:36:56.085741"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b123825a2530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def score_rent(data, target):\n",
    "    X, y = data, target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5, train_size = .8)\n",
    "    pipe = Pipeline((('scaler', StandardScaler()), ('ridge', RidgeCV(alphas=(1.0, 5.0, 10.0, 15.0, 20.0), cv = None, store_cv_values = True))))\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv = KFold(n_splits = 10, shuffle = True, random_state = 5))\n",
    "    return('mean:', np.mean(scores), 'standard deviation:', np.std(scores), 'scores:', scores)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(arr[:,0], bins = 5)\n",
    "\n",
    "\n",
    "def score_rent(data, target):\n",
    "    X, y = data, target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5, train_size = .8)\n",
    "    pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv = KFold(n_splits = 10, shuffle = True, random_state = 5))\n",
    "    return('mean:', np.mean(scores), 'standard deviation:', np.std(scores), 'scores:', scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
